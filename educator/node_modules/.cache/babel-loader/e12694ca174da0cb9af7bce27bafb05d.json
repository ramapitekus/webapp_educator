{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\olesr\\\\OneDrive\\\\Documents\\\\webapp_educ\\\\educator\\\\src\\\\S2t.js\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nconst S2t = props => {\n  console.log(props.audio);\n\n  const sdk = require(\"microsoft-cognitiveservices-speech-sdk\");\n\n  const speechConfig = sdk.SpeechConfig.fromSubscription(\"453a4f6f9f194b9cb503930edaabb2d9\", \"eastus\");\n  speechConfig.speechRecognitionLanguage = \"de-CH\";\n  const reader = new FileReader(); //const audio = null;\n\n  const audio = reader.readAsArrayBuffer(props.audio);\n\n  function fromFile() {\n    let audioConfig = sdk.AudioConfig.fromWavFileInput(audio);\n    let speechRecognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);\n    console.log(audioConfig); //speechRecognizer.recognizeOnceAsync((result) => {\n    //  switch (result.reason) {\n    //    case sdk.ResultReason.RecognizedSpeech:\n    //      console.log(`RECOGNIZED: Text=${result.text}`);\n    //      break;\n    //    case sdk.ResultReason.NoMatch:\n    //      console.log(\"NOMATCH: Speech could not be recognized.\");\n    //      break;\n    //    case sdk.ResultReason.Canceled:\n    //      const cancellation = CancellationDetails.fromResult(result);\n    //      console.log(`CANCELED: Reason=${cancellation.reason}`);\n    //\n    //      if (cancellation.reason == sdk.CancellationReason.Error) {\n    //        console.log(`CANCELED: ErrorCode=${cancellation.ErrorCode}`);\n    //        console.log(`CANCELED: ErrorDetails=${cancellation.errorDetails}`);\n    //        console.log(\n    //          \"CANCELED: Did you update the key and location/region info?\"\n    //        );\n    //      }\n    //      break;\n    //  }\n    //  speechRecognizer.close();\n    //});\n  }\n\n  fromFile();\n  return sdk && /*#__PURE__*/_jsxDEV(\"h1\", {\n    children: \"works\"\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 45,\n    columnNumber: 17\n  }, this);\n};\n\n_c = S2t;\nexport default S2t;\n\nvar _c;\n\n$RefreshReg$(_c, \"S2t\");","map":{"version":3,"sources":["C:/Users/olesr/OneDrive/Documents/webapp_educ/educator/src/S2t.js"],"names":["S2t","props","console","log","audio","sdk","require","speechConfig","SpeechConfig","fromSubscription","speechRecognitionLanguage","reader","FileReader","readAsArrayBuffer","fromFile","audioConfig","AudioConfig","fromWavFileInput","speechRecognizer","SpeechRecognizer"],"mappings":";;;AAAA,MAAMA,GAAG,GAAIC,KAAD,IAAW;AACrBC,EAAAA,OAAO,CAACC,GAAR,CAAYF,KAAK,CAACG,KAAlB;;AACA,QAAMC,GAAG,GAAGC,OAAO,CAAC,wCAAD,CAAnB;;AACA,QAAMC,YAAY,GAAGF,GAAG,CAACG,YAAJ,CAAiBC,gBAAjB,CACnB,kCADmB,EAEnB,QAFmB,CAArB;AAIAF,EAAAA,YAAY,CAACG,yBAAb,GAAyC,OAAzC;AAEA,QAAMC,MAAM,GAAG,IAAIC,UAAJ,EAAf,CATqB,CAUrB;;AACA,QAAMR,KAAK,GAAGO,MAAM,CAACE,iBAAP,CAAyBZ,KAAK,CAACG,KAA/B,CAAd;;AAEA,WAASU,QAAT,GAAoB;AAClB,QAAIC,WAAW,GAAGV,GAAG,CAACW,WAAJ,CAAgBC,gBAAhB,CAAiCb,KAAjC,CAAlB;AACA,QAAIc,gBAAgB,GAAG,IAAIb,GAAG,CAACc,gBAAR,CAAyBZ,YAAzB,EAAuCQ,WAAvC,CAAvB;AACAb,IAAAA,OAAO,CAACC,GAAR,CAAYY,WAAZ,EAHkB,CAKlB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACD;;AACDD,EAAAA,QAAQ;AAER,SAAOT,GAAG,iBAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAAd;AACD,CA7CD;;KAAML,G;AA+CN,eAAeA,GAAf","sourcesContent":["const S2t = (props) => {\r\n  console.log(props.audio);\r\n  const sdk = require(\"microsoft-cognitiveservices-speech-sdk\");\r\n  const speechConfig = sdk.SpeechConfig.fromSubscription(\r\n    \"453a4f6f9f194b9cb503930edaabb2d9\",\r\n    \"eastus\"\r\n  );\r\n  speechConfig.speechRecognitionLanguage = \"de-CH\";\r\n\r\n  const reader = new FileReader();\r\n  //const audio = null;\r\n  const audio = reader.readAsArrayBuffer(props.audio);\r\n\r\n  function fromFile() {\r\n    let audioConfig = sdk.AudioConfig.fromWavFileInput(audio);\r\n    let speechRecognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);\r\n    console.log(audioConfig);\r\n\r\n    //speechRecognizer.recognizeOnceAsync((result) => {\r\n    //  switch (result.reason) {\r\n    //    case sdk.ResultReason.RecognizedSpeech:\r\n    //      console.log(`RECOGNIZED: Text=${result.text}`);\r\n    //      break;\r\n    //    case sdk.ResultReason.NoMatch:\r\n    //      console.log(\"NOMATCH: Speech could not be recognized.\");\r\n    //      break;\r\n    //    case sdk.ResultReason.Canceled:\r\n    //      const cancellation = CancellationDetails.fromResult(result);\r\n    //      console.log(`CANCELED: Reason=${cancellation.reason}`);\r\n    //\r\n    //      if (cancellation.reason == sdk.CancellationReason.Error) {\r\n    //        console.log(`CANCELED: ErrorCode=${cancellation.ErrorCode}`);\r\n    //        console.log(`CANCELED: ErrorDetails=${cancellation.errorDetails}`);\r\n    //        console.log(\r\n    //          \"CANCELED: Did you update the key and location/region info?\"\r\n    //        );\r\n    //      }\r\n    //      break;\r\n    //  }\r\n    //  speechRecognizer.close();\r\n    //});\r\n  }\r\n  fromFile();\r\n\r\n  return sdk && <h1>works</h1>;\r\n};\r\n\r\nexport default S2t;\r\n"]},"metadata":{},"sourceType":"module"}