{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\olesr\\\\OneDrive\\\\Documents\\\\webapp_educ\\\\educator\\\\src\\\\S2t.js\";\nimport { ResultReason } from \"microsoft-cognitiveservices-speech-sdk\";\nimport MyImage from \"./assets/mic.png\";\nimport \"./s2t.css\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\n\nconst S2t = () => {\n  const sdk = require(\"microsoft-cognitiveservices-speech-sdk\");\n\n  async function sttFromMic() {\n    const speechConfig = sdk.SpeechConfig.fromSubscription(\"2ed0fc03d2e441388c4fd35cc91c23b3\", \"eastus\");\n    speechConfig.speechRecognitionLanguage = \"de-CH\";\n    const audioConfig = sdk.AudioConfig.fromDefaultMicrophoneInput();\n    const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);\n    recognizer.recognizeOnceAsync(result => {\n      if (result.reason === ResultReason.RecognizedSpeech) {\n        console.log(result.text);\n      } else {\n        console.log(\"ERROR: Speech was cancelled or could not be recognized. Ensure your microphone is working properly.\");\n      }\n    });\n  }\n\n  return sdk && /*#__PURE__*/_jsxDEV(_Fragment, {\n    children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n      children: \"Speech recognizer\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 32,\n      columnNumber: 9\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"button-record\",\n      children: [/*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: sttFromMic,\n        children: \"SSS\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 34,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n        src: MyImage,\n        alt: \"mic\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 35,\n        columnNumber: 11\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 33,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true);\n};\n\n_c = S2t;\nexport default S2t;\n\nvar _c;\n\n$RefreshReg$(_c, \"S2t\");","map":{"version":3,"sources":["C:/Users/olesr/OneDrive/Documents/webapp_educ/educator/src/S2t.js"],"names":["ResultReason","MyImage","S2t","sdk","require","sttFromMic","speechConfig","SpeechConfig","fromSubscription","speechRecognitionLanguage","audioConfig","AudioConfig","fromDefaultMicrophoneInput","recognizer","SpeechRecognizer","recognizeOnceAsync","result","reason","RecognizedSpeech","console","log","text"],"mappings":";AAAA,SAASA,YAAT,QAA6B,wCAA7B;AACA,OAAOC,OAAP,MAAoB,kBAApB;AACA,OAAO,WAAP;;;;AAEA,MAAMC,GAAG,GAAG,MAAM;AAChB,QAAMC,GAAG,GAAGC,OAAO,CAAC,wCAAD,CAAnB;;AAEA,iBAAeC,UAAf,GAA4B;AAC1B,UAAMC,YAAY,GAAGH,GAAG,CAACI,YAAJ,CAAiBC,gBAAjB,CACnB,kCADmB,EAEnB,QAFmB,CAArB;AAIAF,IAAAA,YAAY,CAACG,yBAAb,GAAyC,OAAzC;AAEA,UAAMC,WAAW,GAAGP,GAAG,CAACQ,WAAJ,CAAgBC,0BAAhB,EAApB;AACA,UAAMC,UAAU,GAAG,IAAIV,GAAG,CAACW,gBAAR,CAAyBR,YAAzB,EAAuCI,WAAvC,CAAnB;AAEAG,IAAAA,UAAU,CAACE,kBAAX,CAA+BC,MAAD,IAAY;AACxC,UAAIA,MAAM,CAACC,MAAP,KAAkBjB,YAAY,CAACkB,gBAAnC,EAAqD;AACnDC,QAAAA,OAAO,CAACC,GAAR,CAAYJ,MAAM,CAACK,IAAnB;AACD,OAFD,MAEO;AACLF,QAAAA,OAAO,CAACC,GAAR,CACE,qGADF;AAGD;AACF,KARD;AASD;;AAED,SACEjB,GAAG,iBACD;AAAA,4BACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YADF,eAEE;AAAK,MAAA,SAAS,EAAC,eAAf;AAAA,8BACE;AAAQ,QAAA,OAAO,EAAEE,UAAjB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cADF,eAEE;AAAK,QAAA,GAAG,EAAEJ,OAAV;AAAmB,QAAA,GAAG,EAAC;AAAvB;AAAA;AAAA;AAAA;AAAA,cAFF;AAAA;AAAA;AAAA;AAAA;AAAA,YAFF;AAAA,kBAFJ;AAWD,CAnCD;;KAAMC,G;AAqCN,eAAeA,GAAf","sourcesContent":["import { ResultReason } from \"microsoft-cognitiveservices-speech-sdk\";\r\nimport MyImage from \"./assets/mic.png\";\r\nimport \"./s2t.css\";\r\n\r\nconst S2t = () => {\r\n  const sdk = require(\"microsoft-cognitiveservices-speech-sdk\");\r\n\r\n  async function sttFromMic() {\r\n    const speechConfig = sdk.SpeechConfig.fromSubscription(\r\n      \"2ed0fc03d2e441388c4fd35cc91c23b3\",\r\n      \"eastus\"\r\n    );\r\n    speechConfig.speechRecognitionLanguage = \"de-CH\";\r\n\r\n    const audioConfig = sdk.AudioConfig.fromDefaultMicrophoneInput();\r\n    const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);\r\n\r\n    recognizer.recognizeOnceAsync((result) => {\r\n      if (result.reason === ResultReason.RecognizedSpeech) {\r\n        console.log(result.text);\r\n      } else {\r\n        console.log(\r\n          \"ERROR: Speech was cancelled or could not be recognized. Ensure your microphone is working properly.\"\r\n        );\r\n      }\r\n    });\r\n  }\r\n\r\n  return (\r\n    sdk && (\r\n      <>\r\n        <h2>Speech recognizer</h2>\r\n        <div className=\"button-record\">\r\n          <button onClick={sttFromMic}>SSS</button>\r\n          <img src={MyImage} alt=\"mic\" />\r\n        </div>\r\n      </>\r\n    )\r\n  );\r\n};\r\n\r\nexport default S2t;\r\n"]},"metadata":{},"sourceType":"module"}