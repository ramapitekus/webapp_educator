{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\olesr\\\\OneDrive\\\\Documents\\\\webapp_educ\\\\educator\\\\src\\\\S2t.js\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\n//import { useRef } from \"react\";\nconst S2t = () => {\n  //var audioCtx = new (window.AudioContext || window.webkitAudioContext)();\n  //var source = audioCtx.createBufferSource();\n  //audioCtx.decodeAudioData(props.audio, function (buffer) {\n  //  source.buffer = buffer;\n  //\n  //  source.connect(audioCtx.destination);\n  //  source.loop = true;\n  //});\n  //const audioArray = useRef(null);\n  //async function convertToArray() {\n  //  const reader = new FileReader();\n  //  reader.onload = function (e) {\n  //    audioArray.current = e.target.result;\n  //  };\n  //  reader.readAsArrayBuffer(props.audio);\n  //}\n  //await convertToArray();\n  const fs = require(\"fs\");\n\n  const sdk = require(\"microsoft-cognitiveservices-speech-sdk\");\n\n  const speechConfig = sdk.SpeechConfig.fromSubscription(\"453a4f6f9f194b9cb503930edaabb2d9\", \"eastus\");\n  speechConfig.speechRecognitionLanguage = \"de-CH\";\n  let audioConfig = sdk.AudioConfig.fromWavFileInput(\"./test.wav\");\n  let speechRecognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);\n  speechRecognizer.recognizeOnceAsync(result => {\n    switch (result.reason) {\n      case sdk.ResultReason.RecognizedSpeech:\n        console.log(`RECOGNIZED: Text=${result.text}`);\n        break;\n\n      case sdk.ResultReason.NoMatch:\n        console.log(\"NOMATCH: Speech could not be recognized.\");\n        break;\n\n      case sdk.ResultReason.Canceled:\n        const cancellation = CancellationDetails.fromResult(result);\n        console.log(`CANCELED: Reason=${cancellation.reason}`);\n\n        if (cancellation.reason == sdk.CancellationReason.Error) {\n          console.log(`CANCELED: ErrorCode=${cancellation.ErrorCode}`);\n          console.log(`CANCELED: ErrorDetails=${cancellation.errorDetails}`);\n          console.log(\"CANCELED: Did you update the key and location/region info?\");\n        }\n\n        break;\n    }\n\n    speechRecognizer.close();\n  });\n  return sdk && /*#__PURE__*/_jsxDEV(\"h1\", {\n    children: \"works\"\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 58,\n    columnNumber: 17\n  }, this);\n};\n\n_c = S2t;\nexport default S2t;\n\nvar _c;\n\n$RefreshReg$(_c, \"S2t\");","map":{"version":3,"sources":["C:/Users/olesr/OneDrive/Documents/webapp_educ/educator/src/S2t.js"],"names":["S2t","fs","require","sdk","speechConfig","SpeechConfig","fromSubscription","speechRecognitionLanguage","audioConfig","AudioConfig","fromWavFileInput","speechRecognizer","SpeechRecognizer","recognizeOnceAsync","result","reason","ResultReason","RecognizedSpeech","console","log","text","NoMatch","Canceled","cancellation","CancellationDetails","fromResult","CancellationReason","Error","ErrorCode","errorDetails","close"],"mappings":";;;AAAA;AAEA,MAAMA,GAAG,GAAG,MAAM;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA,QAAMC,EAAE,GAAGC,OAAO,CAAC,IAAD,CAAlB;;AACA,QAAMC,GAAG,GAAGD,OAAO,CAAC,wCAAD,CAAnB;;AACA,QAAME,YAAY,GAAGD,GAAG,CAACE,YAAJ,CAAiBC,gBAAjB,CACnB,kCADmB,EAEnB,QAFmB,CAArB;AAIAF,EAAAA,YAAY,CAACG,yBAAb,GAAyC,OAAzC;AAEA,MAAIC,WAAW,GAAGL,GAAG,CAACM,WAAJ,CAAgBC,gBAAhB,CAAiC,YAAjC,CAAlB;AACA,MAAIC,gBAAgB,GAAG,IAAIR,GAAG,CAACS,gBAAR,CAAyBR,YAAzB,EAAuCI,WAAvC,CAAvB;AAEAG,EAAAA,gBAAgB,CAACE,kBAAjB,CAAqCC,MAAD,IAAY;AAC9C,YAAQA,MAAM,CAACC,MAAf;AACE,WAAKZ,GAAG,CAACa,YAAJ,CAAiBC,gBAAtB;AACEC,QAAAA,OAAO,CAACC,GAAR,CAAa,oBAAmBL,MAAM,CAACM,IAAK,EAA5C;AACA;;AACF,WAAKjB,GAAG,CAACa,YAAJ,CAAiBK,OAAtB;AACEH,QAAAA,OAAO,CAACC,GAAR,CAAY,0CAAZ;AACA;;AACF,WAAKhB,GAAG,CAACa,YAAJ,CAAiBM,QAAtB;AACE,cAAMC,YAAY,GAAGC,mBAAmB,CAACC,UAApB,CAA+BX,MAA/B,CAArB;AACAI,QAAAA,OAAO,CAACC,GAAR,CAAa,oBAAmBI,YAAY,CAACR,MAAO,EAApD;;AAEA,YAAIQ,YAAY,CAACR,MAAb,IAAuBZ,GAAG,CAACuB,kBAAJ,CAAuBC,KAAlD,EAAyD;AACvDT,UAAAA,OAAO,CAACC,GAAR,CAAa,uBAAsBI,YAAY,CAACK,SAAU,EAA1D;AACAV,UAAAA,OAAO,CAACC,GAAR,CAAa,0BAAyBI,YAAY,CAACM,YAAa,EAAhE;AACAX,UAAAA,OAAO,CAACC,GAAR,CACE,4DADF;AAGD;;AACD;AAlBJ;;AAoBAR,IAAAA,gBAAgB,CAACmB,KAAjB;AACD,GAtBD;AAwBA,SAAO3B,GAAG,iBAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAAd;AACD,CAxDD;;KAAMH,G;AA0DN,eAAeA,GAAf","sourcesContent":["//import { useRef } from \"react\";\r\n\r\nconst S2t = () => {\r\n  //var audioCtx = new (window.AudioContext || window.webkitAudioContext)();\r\n  //var source = audioCtx.createBufferSource();\r\n  //audioCtx.decodeAudioData(props.audio, function (buffer) {\r\n  //  source.buffer = buffer;\r\n  //\r\n  //  source.connect(audioCtx.destination);\r\n  //  source.loop = true;\r\n  //});\r\n  //const audioArray = useRef(null);\r\n\r\n  //async function convertToArray() {\r\n  //  const reader = new FileReader();\r\n  //  reader.onload = function (e) {\r\n  //    audioArray.current = e.target.result;\r\n  //  };\r\n  //  reader.readAsArrayBuffer(props.audio);\r\n  //}\r\n\r\n  //await convertToArray();\r\n  const fs = require(\"fs\");\r\n  const sdk = require(\"microsoft-cognitiveservices-speech-sdk\");\r\n  const speechConfig = sdk.SpeechConfig.fromSubscription(\r\n    \"453a4f6f9f194b9cb503930edaabb2d9\",\r\n    \"eastus\"\r\n  );\r\n  speechConfig.speechRecognitionLanguage = \"de-CH\";\r\n\r\n  let audioConfig = sdk.AudioConfig.fromWavFileInput(\"./test.wav\");\r\n  let speechRecognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);\r\n\r\n  speechRecognizer.recognizeOnceAsync((result) => {\r\n    switch (result.reason) {\r\n      case sdk.ResultReason.RecognizedSpeech:\r\n        console.log(`RECOGNIZED: Text=${result.text}`);\r\n        break;\r\n      case sdk.ResultReason.NoMatch:\r\n        console.log(\"NOMATCH: Speech could not be recognized.\");\r\n        break;\r\n      case sdk.ResultReason.Canceled:\r\n        const cancellation = CancellationDetails.fromResult(result);\r\n        console.log(`CANCELED: Reason=${cancellation.reason}`);\r\n\r\n        if (cancellation.reason == sdk.CancellationReason.Error) {\r\n          console.log(`CANCELED: ErrorCode=${cancellation.ErrorCode}`);\r\n          console.log(`CANCELED: ErrorDetails=${cancellation.errorDetails}`);\r\n          console.log(\r\n            \"CANCELED: Did you update the key and location/region info?\"\r\n          );\r\n        }\r\n        break;\r\n    }\r\n    speechRecognizer.close();\r\n  });\r\n\r\n  return sdk && <h1>works</h1>;\r\n};\r\n\r\nexport default S2t;\r\n"]},"metadata":{},"sourceType":"module"}