{"ast":null,"code":"import { ResultReason } from \"microsoft-cognitiveservices-speech-sdk\";\nimport RecordIcon from \"../assets/mic.png\"; // Unused image for button\n\nimport \"./s2t.css\";\n\nasync function sttFromMic() {\n  const speechConfig = sdk.SpeechConfig.fromSubscription(\"2ed0fc03d2e441388c4fd35cc91c23b3\", \"eastus\");\n  speechConfig.speechRecognitionLanguage = \"de-CH\";\n  const audioConfig = sdk.AudioConfig.fromDefaultMicrophoneInput();\n  const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);\n  recognizer.recognizeOnceAsync(result => {\n    if (result.reason === ResultReason.RecognizedSpeech) {\n      console.log(result.text + \"\\n Recording stopped. Press the streaming button to start again.\");\n      sendToAPI(\"http://localhost:5000/api/v1/models\", result.text).then(response => {\n        console.log(\"Answer from the API:\\n\" + response.message);\n      });\n    } else {\n      console.log(\"ERROR: Speech was cancelled or could not be recognized. Ensure your microphone is working properly.\");\n    }\n  });\n}\n\nasync function sendToAPI(url, message) {\n  // Simple POST request with a JSON body using fetch\n  const requestOptions = {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\"\n    },\n    body: JSON.stringify({\n      message: message\n    })\n  };\n  let response = await fetch(url, requestOptions);\n  return response.json();\n}\n\nexport default S2t;","map":{"version":3,"sources":["C:/Users/olesr/OneDrive/Documents/webapp_educ/educator/src/components/S2t.js"],"names":["ResultReason","RecordIcon","sttFromMic","speechConfig","sdk","SpeechConfig","fromSubscription","speechRecognitionLanguage","audioConfig","AudioConfig","fromDefaultMicrophoneInput","recognizer","SpeechRecognizer","recognizeOnceAsync","result","reason","RecognizedSpeech","console","log","text","sendToAPI","then","response","message","url","requestOptions","method","headers","body","JSON","stringify","fetch","json","S2t"],"mappings":"AAAA,SAASA,YAAT,QAA6B,wCAA7B;AACA,OAAOC,UAAP,MAAuB,mBAAvB,C,CAA4C;;AAC5C,OAAO,WAAP;;AAEA,eAAeC,UAAf,GAA4B;AAC1B,QAAMC,YAAY,GAAGC,GAAG,CAACC,YAAJ,CAAiBC,gBAAjB,CACnB,kCADmB,EAEnB,QAFmB,CAArB;AAIAH,EAAAA,YAAY,CAACI,yBAAb,GAAyC,OAAzC;AACA,QAAMC,WAAW,GAAGJ,GAAG,CAACK,WAAJ,CAAgBC,0BAAhB,EAApB;AACA,QAAMC,UAAU,GAAG,IAAIP,GAAG,CAACQ,gBAAR,CAAyBT,YAAzB,EAAuCK,WAAvC,CAAnB;AACAG,EAAAA,UAAU,CAACE,kBAAX,CAA+BC,MAAD,IAAY;AACxC,QAAIA,MAAM,CAACC,MAAP,KAAkBf,YAAY,CAACgB,gBAAnC,EAAqD;AACnDC,MAAAA,OAAO,CAACC,GAAR,CACEJ,MAAM,CAACK,IAAP,GACE,kEAFJ;AAIAC,MAAAA,SAAS,CAAC,qCAAD,EAAwCN,MAAM,CAACK,IAA/C,CAAT,CAA8DE,IAA9D,CACGC,QAAD,IAAc;AACZL,QAAAA,OAAO,CAACC,GAAR,CAAY,2BAA2BI,QAAQ,CAACC,OAAhD;AACD,OAHH;AAKD,KAVD,MAUO;AACLN,MAAAA,OAAO,CAACC,GAAR,CACE,qGADF;AAGD;AACF,GAhBD;AAiBD;;AAED,eAAeE,SAAf,CAAyBI,GAAzB,EAA8BD,OAA9B,EAAuC;AACrC;AACA,QAAME,cAAc,GAAG;AACrBC,IAAAA,MAAM,EAAE,MADa;AAErBC,IAAAA,OAAO,EAAE;AAAE,sBAAgB;AAAlB,KAFY;AAGrBC,IAAAA,IAAI,EAAEC,IAAI,CAACC,SAAL,CAAe;AAAEP,MAAAA,OAAO,EAAEA;AAAX,KAAf;AAHe,GAAvB;AAMA,MAAID,QAAQ,GAAG,MAAMS,KAAK,CAACP,GAAD,EAAMC,cAAN,CAA1B;AACA,SAAOH,QAAQ,CAACU,IAAT,EAAP;AACD;;AAED,eAAeC,GAAf","sourcesContent":["import { ResultReason } from \"microsoft-cognitiveservices-speech-sdk\";\r\nimport RecordIcon from \"../assets/mic.png\"; // Unused image for button\r\nimport \"./s2t.css\";\r\n\r\nasync function sttFromMic() {\r\n  const speechConfig = sdk.SpeechConfig.fromSubscription(\r\n    \"2ed0fc03d2e441388c4fd35cc91c23b3\",\r\n    \"eastus\"\r\n  );\r\n  speechConfig.speechRecognitionLanguage = \"de-CH\";\r\n  const audioConfig = sdk.AudioConfig.fromDefaultMicrophoneInput();\r\n  const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);\r\n  recognizer.recognizeOnceAsync((result) => {\r\n    if (result.reason === ResultReason.RecognizedSpeech) {\r\n      console.log(\r\n        result.text +\r\n          \"\\n Recording stopped. Press the streaming button to start again.\"\r\n      );\r\n      sendToAPI(\"http://localhost:5000/api/v1/models\", result.text).then(\r\n        (response) => {\r\n          console.log(\"Answer from the API:\\n\" + response.message);\r\n        }\r\n      );\r\n    } else {\r\n      console.log(\r\n        \"ERROR: Speech was cancelled or could not be recognized. Ensure your microphone is working properly.\"\r\n      );\r\n    }\r\n  });\r\n}\r\n\r\nasync function sendToAPI(url, message) {\r\n  // Simple POST request with a JSON body using fetch\r\n  const requestOptions = {\r\n    method: \"POST\",\r\n    headers: { \"Content-Type\": \"application/json\" },\r\n    body: JSON.stringify({ message: message }),\r\n  };\r\n\r\n  let response = await fetch(url, requestOptions);\r\n  return response.json();\r\n}\r\n\r\nexport default S2t;\r\n"]},"metadata":{},"sourceType":"module"}