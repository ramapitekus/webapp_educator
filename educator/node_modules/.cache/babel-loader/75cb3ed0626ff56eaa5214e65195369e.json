{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\olesr\\\\OneDrive\\\\Documents\\\\webapp_educ\\\\educator\\\\src\\\\S2t.js\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\n\n//import { useRef } from \"react\";\nconst S2t = () => {\n  //var audioCtx = new (window.AudioContext || window.webkitAudioContext)();\n  //var source = audioCtx.createBufferSource();\n  //audioCtx.decodeAudioData(props.audio, function (buffer) {\n  //  source.buffer = buffer;\n  //\n  //  source.connect(audioCtx.destination);\n  //  source.loop = true;\n  //});\n  //const audioArray = useRef(null);\n  //async function convertToArray() {\n  //  const reader = new FileReader();\n  //  reader.onload = function (e) {\n  //    audioArray.current = e.target.result;\n  //  };\n  //  reader.readAsArrayBuffer(props.audio);\n  //}\n  //await convertToArray();\n  const sdk = require(\"microsoft-cognitiveservices-speech-sdk\");\n\n  async function sttFromMic() {\n    const speechConfig = sdk.SpeechConfig.fromAuthorizationToken(\"453a4f6f9f194b9cb503930edaabb2d9\", \"eastus\");\n    speechConfig.speechRecognitionLanguage = \"de-CH\";\n    const audioConfig = sdk.AudioConfig.fromDefaultMicrophoneInput();\n    const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);\n    recognizer.recognizeOnceAsync(result => {\n      if (result.reason === ResultReason.RecognizedSpeech) {\n        console.log(result.text);\n      } else {\n        console.log(\"ERROR: Speech was cancelled or could not be recognized. Ensure your microphone is working properly.\");\n      }\n    });\n  } //speechRecognizer.recognizeOnceAsync((result) => {\n  //  switch (result.reason) {\n  //    case sdk.ResultReason.RecognizedSpeech:\n  //      console.log(`RECOGNIZED: Text=${result.text}`);\n  //      break;\n  //    case sdk.ResultReason.NoMatch:\n  //      console.log(\"NOMATCH: Speech could not be recognized.\");\n  //      break;\n  //    case sdk.ResultReason.Canceled:\n  //      //const cancellation = CancellationDetails.fromResult(result);\n  //      console.log(`CANCELED: Reason=`);\n  //\n  //      //if (cancellation.reason == sdk.CancellationReason.Error) {\n  //      //  console.log(`CANCELED: ErrorCode=${cancellation.ErrorCode}`);\n  //      //  console.log(`CANCELED: ErrorDetails=${cancellation.errorDetails}`);\n  //      //  console.log(\n  //      //    \"CANCELED: Did you update the key and location/region info?\"\n  //      //  );\n  //      //}\n  //      break;\n  //  }\n  //  speechRecognizer.close();\n  //});\n\n\n  return sdk && /*#__PURE__*/_jsxDEV(_Fragment, {\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \"works\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 73,\n      columnNumber: 9\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: sttFromMic,\n      children: \"Start\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 74,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true);\n};\n\n_c = S2t;\nexport default S2t;\n\nvar _c;\n\n$RefreshReg$(_c, \"S2t\");","map":{"version":3,"sources":["C:/Users/olesr/OneDrive/Documents/webapp_educ/educator/src/S2t.js"],"names":["S2t","sdk","require","sttFromMic","speechConfig","SpeechConfig","fromAuthorizationToken","speechRecognitionLanguage","audioConfig","AudioConfig","fromDefaultMicrophoneInput","recognizer","SpeechRecognizer","recognizeOnceAsync","result","reason","ResultReason","RecognizedSpeech","console","log","text"],"mappings":";;;;AAAA;AAEA,MAAMA,GAAG,GAAG,MAAM;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA,QAAMC,GAAG,GAAGC,OAAO,CAAC,wCAAD,CAAnB;;AAEA,iBAAeC,UAAf,GAA4B;AAC1B,UAAMC,YAAY,GAAGH,GAAG,CAACI,YAAJ,CAAiBC,sBAAjB,CACnB,kCADmB,EAEnB,QAFmB,CAArB;AAIAF,IAAAA,YAAY,CAACG,yBAAb,GAAyC,OAAzC;AAEA,UAAMC,WAAW,GAAGP,GAAG,CAACQ,WAAJ,CAAgBC,0BAAhB,EAApB;AACA,UAAMC,UAAU,GAAG,IAAIV,GAAG,CAACW,gBAAR,CAAyBR,YAAzB,EAAuCI,WAAvC,CAAnB;AAEAG,IAAAA,UAAU,CAACE,kBAAX,CAA+BC,MAAD,IAAY;AACxC,UAAIA,MAAM,CAACC,MAAP,KAAkBC,YAAY,CAACC,gBAAnC,EAAqD;AACnDC,QAAAA,OAAO,CAACC,GAAR,CAAYL,MAAM,CAACM,IAAnB;AACD,OAFD,MAEO;AACLF,QAAAA,OAAO,CAACC,GAAR,CACE,qGADF;AAGD;AACF,KARD;AASD,GAzCe,CA2ChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAEA,SACElB,GAAG,iBACD;AAAA,4BACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YADF,eAEE;AAAQ,MAAA,OAAO,EAAEE,UAAjB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAFF;AAAA,kBAFJ;AAQD,CA3ED;;KAAMH,G;AA6EN,eAAeA,GAAf","sourcesContent":["//import { useRef } from \"react\";\r\n\r\nconst S2t = () => {\r\n  //var audioCtx = new (window.AudioContext || window.webkitAudioContext)();\r\n  //var source = audioCtx.createBufferSource();\r\n  //audioCtx.decodeAudioData(props.audio, function (buffer) {\r\n  //  source.buffer = buffer;\r\n  //\r\n  //  source.connect(audioCtx.destination);\r\n  //  source.loop = true;\r\n  //});\r\n  //const audioArray = useRef(null);\r\n\r\n  //async function convertToArray() {\r\n  //  const reader = new FileReader();\r\n  //  reader.onload = function (e) {\r\n  //    audioArray.current = e.target.result;\r\n  //  };\r\n  //  reader.readAsArrayBuffer(props.audio);\r\n  //}\r\n\r\n  //await convertToArray();\r\n  const sdk = require(\"microsoft-cognitiveservices-speech-sdk\");\r\n\r\n  async function sttFromMic() {\r\n    const speechConfig = sdk.SpeechConfig.fromAuthorizationToken(\r\n      \"453a4f6f9f194b9cb503930edaabb2d9\",\r\n      \"eastus\"\r\n    );\r\n    speechConfig.speechRecognitionLanguage = \"de-CH\";\r\n\r\n    const audioConfig = sdk.AudioConfig.fromDefaultMicrophoneInput();\r\n    const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);\r\n\r\n    recognizer.recognizeOnceAsync((result) => {\r\n      if (result.reason === ResultReason.RecognizedSpeech) {\r\n        console.log(result.text);\r\n      } else {\r\n        console.log(\r\n          \"ERROR: Speech was cancelled or could not be recognized. Ensure your microphone is working properly.\"\r\n        );\r\n      }\r\n    });\r\n  }\r\n\r\n  //speechRecognizer.recognizeOnceAsync((result) => {\r\n  //  switch (result.reason) {\r\n  //    case sdk.ResultReason.RecognizedSpeech:\r\n  //      console.log(`RECOGNIZED: Text=${result.text}`);\r\n  //      break;\r\n  //    case sdk.ResultReason.NoMatch:\r\n  //      console.log(\"NOMATCH: Speech could not be recognized.\");\r\n  //      break;\r\n  //    case sdk.ResultReason.Canceled:\r\n  //      //const cancellation = CancellationDetails.fromResult(result);\r\n  //      console.log(`CANCELED: Reason=`);\r\n  //\r\n  //      //if (cancellation.reason == sdk.CancellationReason.Error) {\r\n  //      //  console.log(`CANCELED: ErrorCode=${cancellation.ErrorCode}`);\r\n  //      //  console.log(`CANCELED: ErrorDetails=${cancellation.errorDetails}`);\r\n  //      //  console.log(\r\n  //      //    \"CANCELED: Did you update the key and location/region info?\"\r\n  //      //  );\r\n  //      //}\r\n  //      break;\r\n  //  }\r\n  //  speechRecognizer.close();\r\n  //});\r\n\r\n  return (\r\n    sdk && (\r\n      <>\r\n        <h1>works</h1>\r\n        <button onClick={sttFromMic}>Start</button>\r\n      </>\r\n    )\r\n  );\r\n};\r\n\r\nexport default S2t;\r\n"]},"metadata":{},"sourceType":"module"}