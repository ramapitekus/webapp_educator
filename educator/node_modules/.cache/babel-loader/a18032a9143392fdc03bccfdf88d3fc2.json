{"ast":null,"code":"import { ResultReason } from \"microsoft-cognitiveservices-speech-sdk\";\n\nfunction sttFromMic(handleCallback) {\n  const sdk = require(\"microsoft-cognitiveservices-speech-sdk\");\n\n  const speechConfig = sdk.SpeechConfig.fromSubscription(\"2ed0fc03d2e441388c4fd35cc91c23b3\", \"eastus\");\n  speechConfig.speechRecognitionLanguage = \"de-CH\";\n  const audioConfig = sdk.AudioConfig.fromDefaultMicrophoneInput();\n  const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);\n\n  async function startRecording() {\n    recognizer.startContinuousRecognitionAsync(); // Add error handling\n\n    recognizer.recognized = (_, e) => {\n      var result = e.result;\n\n      if (result.reason === ResultReason.RecognizedSpeech) {\n        console.log(result.text);\n        sendToAPI(\"http://localhost:5000/api/v1/models\", result.text).then(response => {\n          console.log(\"Answer from the API:\\n\" + response.message + \"\\nAPI recognized following topic:\\n\" + response.topic);\n          handleCallback(response.topic);\n        });\n      } else {\n        console.log(\"ERROR: Speech was cancelled or could not be recognized. Ensure your microphone is working properly.\");\n      }\n    };\n  }\n\n  async function stopRecording() {\n    recognizer.stopContinuousRecognitionAsync();\n  }\n\n  return [startRecording, stopRecording];\n}\n\nasync function sendToAPI(url, message) {\n  // Simple POST request with a JSON body using fetch\n  const requestOptions = {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\"\n    },\n    body: JSON.stringify({\n      message: message\n    })\n  };\n  let response = await fetch(url, requestOptions);\n  return response.json();\n}\n\nexport default sttFromMic;","map":{"version":3,"sources":["C:/Users/olesr/OneDrive/Documents/webapp_educ/educator/src/components/S2t.js"],"names":["ResultReason","sttFromMic","handleCallback","sdk","require","speechConfig","SpeechConfig","fromSubscription","speechRecognitionLanguage","audioConfig","AudioConfig","fromDefaultMicrophoneInput","recognizer","SpeechRecognizer","startRecording","startContinuousRecognitionAsync","recognized","_","e","result","reason","RecognizedSpeech","console","log","text","sendToAPI","then","response","message","topic","stopRecording","stopContinuousRecognitionAsync","url","requestOptions","method","headers","body","JSON","stringify","fetch","json"],"mappings":"AAAA,SAASA,YAAT,QAA6B,wCAA7B;;AAEA,SAASC,UAAT,CAAoBC,cAApB,EAAoC;AAClC,QAAMC,GAAG,GAAGC,OAAO,CAAC,wCAAD,CAAnB;;AACA,QAAMC,YAAY,GAAGF,GAAG,CAACG,YAAJ,CAAiBC,gBAAjB,CACnB,kCADmB,EAEnB,QAFmB,CAArB;AAIAF,EAAAA,YAAY,CAACG,yBAAb,GAAyC,OAAzC;AACA,QAAMC,WAAW,GAAGN,GAAG,CAACO,WAAJ,CAAgBC,0BAAhB,EAApB;AACA,QAAMC,UAAU,GAAG,IAAIT,GAAG,CAACU,gBAAR,CAAyBR,YAAzB,EAAuCI,WAAvC,CAAnB;;AAEA,iBAAeK,cAAf,GAAgC;AAC9BF,IAAAA,UAAU,CAACG,+BAAX,GAD8B,CAE9B;;AACAH,IAAAA,UAAU,CAACI,UAAX,GAAwB,CAACC,CAAD,EAAIC,CAAJ,KAAU;AAChC,UAAIC,MAAM,GAAGD,CAAC,CAACC,MAAf;;AACA,UAAIA,MAAM,CAACC,MAAP,KAAkBpB,YAAY,CAACqB,gBAAnC,EAAqD;AACnDC,QAAAA,OAAO,CAACC,GAAR,CAAYJ,MAAM,CAACK,IAAnB;AACAC,QAAAA,SAAS,CAAC,qCAAD,EAAwCN,MAAM,CAACK,IAA/C,CAAT,CAA8DE,IAA9D,CACGC,QAAD,IAAc;AACZL,UAAAA,OAAO,CAACC,GAAR,CACE,2BACEI,QAAQ,CAACC,OADX,GAEE,qCAFF,GAGED,QAAQ,CAACE,KAJb;AAMA3B,UAAAA,cAAc,CAACyB,QAAQ,CAACE,KAAV,CAAd;AACD,SATH;AAWD,OAbD,MAaO;AACLP,QAAAA,OAAO,CAACC,GAAR,CACE,qGADF;AAGD;AACF,KApBD;AAqBD;;AACD,iBAAeO,aAAf,GAA+B;AAC7BlB,IAAAA,UAAU,CAACmB,8BAAX;AACD;;AACD,SAAO,CAACjB,cAAD,EAAiBgB,aAAjB,CAAP;AACD;;AAED,eAAeL,SAAf,CAAyBO,GAAzB,EAA8BJ,OAA9B,EAAuC;AACrC;AACA,QAAMK,cAAc,GAAG;AACrBC,IAAAA,MAAM,EAAE,MADa;AAErBC,IAAAA,OAAO,EAAE;AAAE,sBAAgB;AAAlB,KAFY;AAGrBC,IAAAA,IAAI,EAAEC,IAAI,CAACC,SAAL,CAAe;AAAEV,MAAAA,OAAO,EAAEA;AAAX,KAAf;AAHe,GAAvB;AAMA,MAAID,QAAQ,GAAG,MAAMY,KAAK,CAACP,GAAD,EAAMC,cAAN,CAA1B;AACA,SAAON,QAAQ,CAACa,IAAT,EAAP;AACD;;AAED,eAAevC,UAAf","sourcesContent":["import { ResultReason } from \"microsoft-cognitiveservices-speech-sdk\";\r\n\r\nfunction sttFromMic(handleCallback) {\r\n  const sdk = require(\"microsoft-cognitiveservices-speech-sdk\");\r\n  const speechConfig = sdk.SpeechConfig.fromSubscription(\r\n    \"2ed0fc03d2e441388c4fd35cc91c23b3\",\r\n    \"eastus\"\r\n  );\r\n  speechConfig.speechRecognitionLanguage = \"de-CH\";\r\n  const audioConfig = sdk.AudioConfig.fromDefaultMicrophoneInput();\r\n  const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);\r\n\r\n  async function startRecording() {\r\n    recognizer.startContinuousRecognitionAsync();\r\n    // Add error handling\r\n    recognizer.recognized = (_, e) => {\r\n      var result = e.result;\r\n      if (result.reason === ResultReason.RecognizedSpeech) {\r\n        console.log(result.text);\r\n        sendToAPI(\"http://localhost:5000/api/v1/models\", result.text).then(\r\n          (response) => {\r\n            console.log(\r\n              \"Answer from the API:\\n\" +\r\n                response.message +\r\n                \"\\nAPI recognized following topic:\\n\" +\r\n                response.topic\r\n            );\r\n            handleCallback(response.topic);\r\n          }\r\n        );\r\n      } else {\r\n        console.log(\r\n          \"ERROR: Speech was cancelled or could not be recognized. Ensure your microphone is working properly.\"\r\n        );\r\n      }\r\n    };\r\n  }\r\n  async function stopRecording() {\r\n    recognizer.stopContinuousRecognitionAsync();\r\n  }\r\n  return [startRecording, stopRecording];\r\n}\r\n\r\nasync function sendToAPI(url, message) {\r\n  // Simple POST request with a JSON body using fetch\r\n  const requestOptions = {\r\n    method: \"POST\",\r\n    headers: { \"Content-Type\": \"application/json\" },\r\n    body: JSON.stringify({ message: message }),\r\n  };\r\n\r\n  let response = await fetch(url, requestOptions);\r\n  return response.json();\r\n}\r\n\r\nexport default sttFromMic;\r\n"]},"metadata":{},"sourceType":"module"}