{"ast":null,"code":"// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\r\n * Represents the JSON used in the synthesis.context message sent to the speech service.\r\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\r\n */\nexport class SynthesisContext {\n  constructor(speechSynthesizer) {\n    this.privContext = {};\n    this.privSpeechSynthesizer = speechSynthesizer;\n  }\n  /**\r\n   * Adds a section to the synthesis.context object.\r\n   * @param sectionName Name of the section to add.\r\n   * @param value JSON serializable object that represents the value.\r\n   */\n\n\n  setSection(sectionName, value) {\n    this.privContext[sectionName] = value;\n  }\n  /**\r\n   * Sets the audio output format for synthesis context generation.\r\n   * @param format {AudioOutputFormatImpl} the output format\r\n   */\n\n\n  set audioOutputFormat(format) {\n    this.privAudioOutputFormat = format;\n  }\n\n  toJSON() {\n    const synthesisSection = this.buildSynthesisContext();\n    this.setSection(\"synthesis\", synthesisSection);\n    return JSON.stringify(this.privContext);\n  }\n\n  buildSynthesisContext() {\n    return {\n      audio: {\n        metadataOptions: {\n          bookmarkEnabled: !!this.privSpeechSynthesizer.bookmarkReached,\n          sentenceBoundaryEnabled: false,\n          visemeEnabled: !!this.privSpeechSynthesizer.visemeReceived,\n          wordBoundaryEnabled: !!this.privSpeechSynthesizer.wordBoundary\n        },\n        outputFormat: this.privAudioOutputFormat.requestAudioFormatString\n      },\n      language: {\n        autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\n      }\n    };\n  }\n\n}","map":{"version":3,"mappings":"AAAA;AACA;;AAKA;;;;AAIA,OAAM,MAAOA,gBAAP,CAAuB;AAKzBC,cAAYC,iBAAZ,EAAgD;AAJxC,uBAA0C,EAA1C;AAKJ,SAAKC,qBAAL,GAA6BD,iBAA7B;AACH;AAED;;;;;;;AAKOE,YAAU,CAACC,WAAD,EAAsBC,KAAtB,EAAgC;AAC7C,SAAKC,WAAL,CAAiBF,WAAjB,IAAgCC,KAAhC;AACH;AAED;;;;;;AAI4B,MAAjBE,iBAAiB,CAACC,MAAD,EAA8B;AACtD,SAAKC,qBAAL,GAA6BD,MAA7B;AACH;;AAEME,QAAM;AAET,UAAMC,gBAAgB,GAAsB,KAAKC,qBAAL,EAA5C;AACA,SAAKT,UAAL,CAAgB,WAAhB,EAA6BQ,gBAA7B;AAEA,WAAOE,IAAI,CAACC,SAAL,CAAe,KAAKR,WAApB,CAAP;AACH;;AAEOM,uBAAqB;AACzB,WAAO;AACHG,WAAK,EAAE;AACHC,uBAAe,EAAE;AACbC,yBAAe,EAAG,CAAC,CAAC,KAAKf,qBAAL,CAA2BgB,eADlC;AAEbC,iCAAuB,EAAE,KAFZ;AAGbC,uBAAa,EAAG,CAAC,CAAC,KAAKlB,qBAAL,CAA2BmB,cAHhC;AAIbC,6BAAmB,EAAG,CAAC,CAAC,KAAKpB,qBAAL,CAA2BqB;AAJtC,SADd;AAOHC,oBAAY,EAAE,KAAKf,qBAAL,CAA2BgB;AAPtC,OADJ;AAUHC,cAAQ,EAAE;AACNC,qBAAa,EAAE,KAAKzB,qBAAL,CAA2B0B;AADpC;AAVP,KAAP;AAcH;;AAjDwB","names":["SynthesisContext","constructor","speechSynthesizer","privSpeechSynthesizer","setSection","sectionName","value","privContext","audioOutputFormat","format","privAudioOutputFormat","toJSON","synthesisSection","buildSynthesisContext","JSON","stringify","audio","metadataOptions","bookmarkEnabled","bookmarkReached","sentenceBoundaryEnabled","visemeEnabled","visemeReceived","wordBoundaryEnabled","wordBoundary","outputFormat","requestAudioFormatString","language","autoDetection","autoDetectSourceLanguage"],"sources":["C:\\Users\\olesr\\OneDrive\\Documents\\webapp_educ\\educator\\node_modules\\microsoft-cognitiveservices-speech-sdk\\distrib\\es2015\\src\\common.speech\\src\\common.speech\\SynthesisContext.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT license.\r\n\r\nimport { AudioOutputFormatImpl } from \"../sdk/Audio/AudioOutputFormat\";\r\nimport { SpeechSynthesizer } from \"../sdk/Exports\";\r\n\r\n/**\r\n * Represents the JSON used in the synthesis.context message sent to the speech service.\r\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\r\n */\r\nexport class SynthesisContext {\r\n    private privContext: { [section: string]: any } = {};\r\n    private privSpeechSynthesizer: SpeechSynthesizer;\r\n    private privAudioOutputFormat: AudioOutputFormatImpl;\r\n\r\n    constructor(speechSynthesizer: SpeechSynthesizer) {\r\n        this.privSpeechSynthesizer = speechSynthesizer;\r\n    }\r\n\r\n    /**\r\n     * Adds a section to the synthesis.context object.\r\n     * @param sectionName Name of the section to add.\r\n     * @param value JSON serializable object that represents the value.\r\n     */\r\n    public setSection(sectionName: string, value: any): void {\r\n        this.privContext[sectionName] = value;\r\n    }\r\n\r\n    /**\r\n     * Sets the audio output format for synthesis context generation.\r\n     * @param format {AudioOutputFormatImpl} the output format\r\n     */\r\n    public set audioOutputFormat(format: AudioOutputFormatImpl) {\r\n        this.privAudioOutputFormat = format;\r\n    }\r\n\r\n    public toJSON(): string {\r\n\r\n        const synthesisSection: ISynthesisSection = this.buildSynthesisContext();\r\n        this.setSection(\"synthesis\", synthesisSection);\r\n\r\n        return JSON.stringify(this.privContext);\r\n    }\r\n\r\n    private buildSynthesisContext(): ISynthesisSection {\r\n        return {\r\n            audio: {\r\n                metadataOptions: {\r\n                    bookmarkEnabled: (!!this.privSpeechSynthesizer.bookmarkReached),\r\n                    sentenceBoundaryEnabled: false,\r\n                    visemeEnabled: (!!this.privSpeechSynthesizer.visemeReceived),\r\n                    wordBoundaryEnabled: (!!this.privSpeechSynthesizer.wordBoundary),\r\n                },\r\n                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,\r\n            },\r\n            language: {\r\n                autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\r\n            }\r\n        };\r\n    }\r\n}\r\n\r\ninterface ISynthesisSection {\r\n    audio: {\r\n        outputFormat: string,\r\n        metadataOptions: {\r\n            bookmarkEnabled: boolean,\r\n            wordBoundaryEnabled: boolean,\r\n            visemeEnabled: boolean,\r\n            sentenceBoundaryEnabled: boolean,\r\n        }\r\n    };\r\n    language: {\r\n        autoDetection: boolean\r\n    };\r\n}\r\n"]},"metadata":{},"sourceType":"module"}