{"ast":null,"code":"// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines speech property ids.\n * @class PropertyId\n */\nexport var PropertyId;\n\n(function (PropertyId) {\n  /**\n   * The Cognitive Services Speech Service subscription Key. If you are using an intent recognizer, you need to specify\n   * to specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't\n   * have to use this property directly.\n   * Instead, use [[SpeechConfig.fromSubscription]].\n   * @member PropertyId.SpeechServiceConnection_Key\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Key\"] = 0] = \"SpeechServiceConnection_Key\";\n  /**\n   * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't\n   * have to use this property directly.\n   * Instead, use [[SpeechConfig.fromEndpoint]].\n   * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.\n   * @member PropertyId.SpeechServiceConnection_Endpoint\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_Endpoint\"] = 1] = \"SpeechServiceConnection_Endpoint\";\n  /**\n   * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to\n   * use this property directly.\n   * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].\n   * @member PropertyId.SpeechServiceConnection_Region\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_Region\"] = 2] = \"SpeechServiceConnection_Region\";\n  /**\n   * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,\n   * you shouldn't have to use this property directly.\n   * Instead, use [[SpeechConfig.fromAuthorizationToken]], [[SpeechRecognizer.authorizationToken]],\n   * [[IntentRecognizer.authorizationToken]], [[TranslationRecognizer.authorizationToken]], [[SpeakerRecognizer.authorizationToken]].\n   * @member PropertyId.SpeechServiceAuthorization_Token\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceAuthorization_Token\"] = 3] = \"SpeechServiceAuthorization_Token\";\n  /**\n   * The Cognitive Services Speech Service authorization type. Currently unused.\n   * @member PropertyId.SpeechServiceAuthorization_Type\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceAuthorization_Type\"] = 4] = \"SpeechServiceAuthorization_Type\";\n  /**\n   * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't\n   * have to use this property directly.\n   * Instead, use [[SpeechConfig.endpointId]].\n   * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.\n   * @member PropertyId.SpeechServiceConnection_EndpointId\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_EndpointId\"] = 5] = \"SpeechServiceConnection_EndpointId\";\n  /**\n   * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,\n   * you shouldn't have to use this property directly.\n   * Instead use [[SpeechTranslationConfig.addTargetLanguage]],\n   * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].\n   * @member PropertyId.SpeechServiceConnection_TranslationToLanguages\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_TranslationToLanguages\"] = 6] = \"SpeechServiceConnection_TranslationToLanguages\";\n  /**\n   * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this\n   * property directly.\n   * Instead, use [[SpeechTranslationConfig.voiceName]].\n   * NOTE: Valid voice names can be found <a href=\"https://aka.ms/csspeech/voicenames\">here</a>.\n   * @member PropertyId.SpeechServiceConnection_TranslationVoice\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_TranslationVoice\"] = 7] = \"SpeechServiceConnection_TranslationVoice\";\n  /**\n   * Translation features.\n   * @member PropertyId.SpeechServiceConnection_TranslationFeatures\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_TranslationFeatures\"] = 8] = \"SpeechServiceConnection_TranslationFeatures\";\n  /**\n   * The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.\n   * Instead, use [[LanguageUnderstandingModel]].\n   * @member PropertyId.SpeechServiceConnection_IntentRegion\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_IntentRegion\"] = 9] = \"SpeechServiceConnection_IntentRegion\";\n  /**\n   * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyHostName\"] = 10] = \"SpeechServiceConnection_ProxyHostName\";\n  /**\n   * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyPort\"] = 11] = \"SpeechServiceConnection_ProxyPort\";\n  /**\n   * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyUserName\"] = 12] = \"SpeechServiceConnection_ProxyUserName\";\n  /**\n   * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyPassword\"] = 13] = \"SpeechServiceConnection_ProxyPassword\";\n  /**\n   * The Cognitive Services Speech Service recognition Mode. Can be \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\".\n   * This property is intended to be read-only. The SDK is using it internally.\n   * @member PropertyId.SpeechServiceConnection_RecoMode\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_RecoMode\"] = 14] = \"SpeechServiceConnection_RecoMode\";\n  /**\n   * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property\n   * directly.\n   * Instead, use [[SpeechConfig.speechRecognitionLanguage]].\n   * @member PropertyId.SpeechServiceConnection_RecoLanguage\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_RecoLanguage\"] = 15] = \"SpeechServiceConnection_RecoLanguage\";\n  /**\n   * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream\n   * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this\n   * property directly.\n   * Instead use [[SessionEventArgs.sessionId]].\n   * @member PropertyId.Speech_SessionId\n   */\n\n  PropertyId[PropertyId[\"Speech_SessionId\"] = 16] = \"Speech_SessionId\";\n  /**\n   * The spoken language to be synthesized (e.g. en-US)\n   * @member PropertyId.SpeechServiceConnection_SynthLanguage\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_SynthLanguage\"] = 17] = \"SpeechServiceConnection_SynthLanguage\";\n  /**\n   * The name of the TTS voice to be used for speech synthesis\n   * @member PropertyId.SpeechServiceConnection_SynthVoice\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_SynthVoice\"] = 18] = \"SpeechServiceConnection_SynthVoice\";\n  /**\n   * The string to specify TTS output audio format\n   * @member PropertyId.SpeechServiceConnection_SynthOutputFormat\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_SynthOutputFormat\"] = 19] = \"SpeechServiceConnection_SynthOutputFormat\";\n  /**\n   * The list of comma separated languages used as possible source languages\n   * Added in version 1.13.0\n   * @member PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_AutoDetectSourceLanguages\"] = 20] = \"SpeechServiceConnection_AutoDetectSourceLanguages\";\n  /**\n   * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have\n   * to use this property directly.\n   * Instead use [[SpeechConfig.outputFormat]].\n   * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestDetailedResultTrueFalse\"] = 21] = \"SpeechServiceResponse_RequestDetailedResultTrueFalse\";\n  /**\n   * The requested Cognitive Services Speech Service response output profanity level. Currently unused.\n   * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestProfanityFilterTrueFalse\"] = 22] = \"SpeechServiceResponse_RequestProfanityFilterTrueFalse\";\n  /**\n   * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.\n   * @member PropertyId.SpeechServiceResponse_JsonResult\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceResponse_JsonResult\"] = 23] = \"SpeechServiceResponse_JsonResult\";\n  /**\n   * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to\n   * use this property directly. Instead use [[CancellationDetails.errorDetails]].\n   * @member PropertyId.SpeechServiceResponse_JsonErrorDetails\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceResponse_JsonErrorDetails\"] = 24] = \"SpeechServiceResponse_JsonErrorDetails\";\n  /**\n   * The cancellation reason. Currently unused.\n   * @member PropertyId.CancellationDetails_Reason\n   */\n\n  PropertyId[PropertyId[\"CancellationDetails_Reason\"] = 25] = \"CancellationDetails_Reason\";\n  /**\n   * The cancellation text. Currently unused.\n   * @member PropertyId.CancellationDetails_ReasonText\n   */\n\n  PropertyId[PropertyId[\"CancellationDetails_ReasonText\"] = 26] = \"CancellationDetails_ReasonText\";\n  /**\n   * The Cancellation detailed text. Currently unused.\n   * @member PropertyId.CancellationDetails_ReasonDetailedText\n   */\n\n  PropertyId[PropertyId[\"CancellationDetails_ReasonDetailedText\"] = 27] = \"CancellationDetails_ReasonDetailedText\";\n  /**\n   * The Language Understanding Service response output (in JSON format). Available via [[IntentRecognitionResult]]\n   * @member PropertyId.LanguageUnderstandingServiceResponse_JsonResult\n   */\n\n  PropertyId[PropertyId[\"LanguageUnderstandingServiceResponse_JsonResult\"] = 28] = \"LanguageUnderstandingServiceResponse_JsonResult\";\n  /**\n   * The URL string built from speech configuration.\n   * This property is intended to be read-only. The SDK is using it internally.\n   * NOTE: Added in version 1.7.0.\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_Url\"] = 29] = \"SpeechServiceConnection_Url\";\n  /**\n   * The initial silence timeout value (in milliseconds) used by the service.\n   * Added in version 1.7.0\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_InitialSilenceTimeoutMs\"] = 30] = \"SpeechServiceConnection_InitialSilenceTimeoutMs\";\n  /**\n   * The end silence timeout value (in milliseconds) used by the service.\n   * Added in version 1.7.0\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_EndSilenceTimeoutMs\"] = 31] = \"SpeechServiceConnection_EndSilenceTimeoutMs\";\n  /**\n   * A boolean value specifying whether audio logging is enabled in the service or not.\n   * Added in version 1.7.0\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_EnableAudioLogging\"] = 32] = \"SpeechServiceConnection_EnableAudioLogging\";\n  /**\n   * The requested Cognitive Services Speech Service response output profanity setting.\n   * Allowed values are \"masked\", \"removed\", and \"raw\".\n   * Added in version 1.7.0.\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceResponse_ProfanityOption\"] = 33] = \"SpeechServiceResponse_ProfanityOption\";\n  /**\n   * A string value specifying which post processing option should be used by service.\n   * Allowed values are \"TrueText\".\n   * Added in version 1.7.0\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceResponse_PostProcessingOption\"] = 34] = \"SpeechServiceResponse_PostProcessingOption\";\n  /**\n   *  A boolean value specifying whether to include word-level timestamps in the response result.\n   * Added in version 1.7.0\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestWordLevelTimestamps\"] = 35] = \"SpeechServiceResponse_RequestWordLevelTimestamps\";\n  /**\n   * The number of times a word has to be in partial results to be returned.\n   * Added in version 1.7.0\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceResponse_StablePartialResultThreshold\"] = 36] = \"SpeechServiceResponse_StablePartialResultThreshold\";\n  /**\n   * A string value specifying the output format option in the response result. Internal use only.\n   * Added in version 1.7.0.\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceResponse_OutputFormatOption\"] = 37] = \"SpeechServiceResponse_OutputFormatOption\";\n  /**\n   * A boolean value to request for stabilizing translation partial results by omitting words in the end.\n   * Added in version 1.7.0.\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceResponse_TranslationRequestStablePartialResult\"] = 38] = \"SpeechServiceResponse_TranslationRequestStablePartialResult\";\n  /**\n   * Identifier used to connect to the backend service.\n   * @member PropertyId.Conversation_ApplicationId\n   */\n\n  PropertyId[PropertyId[\"Conversation_ApplicationId\"] = 39] = \"Conversation_ApplicationId\";\n  /**\n   * Type of dialog backend to connect to.\n   * @member PropertyId.Conversation_DialogType\n   */\n\n  PropertyId[PropertyId[\"Conversation_DialogType\"] = 40] = \"Conversation_DialogType\";\n  /**\n   * Silence timeout for listening\n   * @member PropertyId.Conversation_Initial_Silence_Timeout\n   */\n\n  PropertyId[PropertyId[\"Conversation_Initial_Silence_Timeout\"] = 41] = \"Conversation_Initial_Silence_Timeout\";\n  /**\n   * From Id to add to speech recognition activities.\n   * @member PropertyId.Conversation_From_Id\n   */\n\n  PropertyId[PropertyId[\"Conversation_From_Id\"] = 42] = \"Conversation_From_Id\";\n  /**\n   * ConversationId for the session.\n   * @member PropertyId.Conversation_Conversation_Id\n   */\n\n  PropertyId[PropertyId[\"Conversation_Conversation_Id\"] = 43] = \"Conversation_Conversation_Id\";\n  /**\n   * Comma separated list of custom voice deployment ids.\n   * @member PropertyId.Conversation_Custom_Voice_Deployment_Ids\n   */\n\n  PropertyId[PropertyId[\"Conversation_Custom_Voice_Deployment_Ids\"] = 44] = \"Conversation_Custom_Voice_Deployment_Ids\";\n  /**\n   * Speech activity template, stamp properties from the template on the activity generated by the service for speech.\n   * @member PropertyId.Conversation_Speech_Activity_Template\n   * Added in version 1.10.0.\n   */\n\n  PropertyId[PropertyId[\"Conversation_Speech_Activity_Template\"] = 45] = \"Conversation_Speech_Activity_Template\";\n  /**\n   * Enables or disables the receipt of turn status messages as obtained on the turnStatusReceived event.\n   * @member PropertyId.Conversation_Request_Bot_Status_Messages\n   * Added in version 1.15.0.\n   */\n\n  PropertyId[PropertyId[\"Conversation_Request_Bot_Status_Messages\"] = 46] = \"Conversation_Request_Bot_Status_Messages\";\n  /**\n   * Specifies the connection ID to be provided in the Agent configuration message, e.g. a Direct Line token for\n   * channel authentication.\n   * Added in version 1.15.1.\n   */\n\n  PropertyId[PropertyId[\"Conversation_Agent_Connection_Id\"] = 47] = \"Conversation_Agent_Connection_Id\";\n  /**\n   * The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.\n   * Instead, use [[SpeechConfig.fromHost]].\n   */\n\n  PropertyId[PropertyId[\"SpeechServiceConnection_Host\"] = 48] = \"SpeechServiceConnection_Host\";\n  /**\n   * Set the host for service calls to the Conversation Translator REST management and websocket calls.\n   */\n\n  PropertyId[PropertyId[\"ConversationTranslator_Host\"] = 49] = \"ConversationTranslator_Host\";\n  /**\n   * Optionally set the the host's display name.\n   * Used when joining a conversation.\n   */\n\n  PropertyId[PropertyId[\"ConversationTranslator_Name\"] = 50] = \"ConversationTranslator_Name\";\n  /**\n   * Optionally set a value for the X-CorrelationId request header.\n   * Used for troubleshooting errors in the server logs. It should be a valid guid.\n   */\n\n  PropertyId[PropertyId[\"ConversationTranslator_CorrelationId\"] = 51] = \"ConversationTranslator_CorrelationId\";\n  /**\n   * Set the conversation token to be sent to the speech service. This enables the\n   * service to service call from the speech service to the Conversation Translator service for relaying\n   * recognitions. For internal use.\n   */\n\n  PropertyId[PropertyId[\"ConversationTranslator_Token\"] = 52] = \"ConversationTranslator_Token\";\n  /**\n   * The reference text of the audio for pronunciation evaluation.\n   * For this and the following pronunciation assessment parameters, see\n   * https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n\n  PropertyId[PropertyId[\"PronunciationAssessment_ReferenceText\"] = 53] = \"PronunciationAssessment_ReferenceText\";\n  /**\n   * The point system for pronunciation score calibration (FivePoint or HundredMark).\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n\n  PropertyId[PropertyId[\"PronunciationAssessment_GradingSystem\"] = 54] = \"PronunciationAssessment_GradingSystem\";\n  /**\n   * The pronunciation evaluation granularity (Phoneme, Word, or FullText).\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n\n  PropertyId[PropertyId[\"PronunciationAssessment_Granularity\"] = 55] = \"PronunciationAssessment_Granularity\";\n  /**\n   * Defines if enable miscue calculation.\n   * With this enabled, the pronounced words will be compared to the reference text,\n   * and will be marked with omission/insertion based on the comparison. The default setting is False.\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n\n  PropertyId[PropertyId[\"PronunciationAssessment_EnableMiscue\"] = 56] = \"PronunciationAssessment_EnableMiscue\";\n  /**\n   * The json string of pronunciation assessment parameters\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n\n  PropertyId[PropertyId[\"PronunciationAssessment_Json\"] = 57] = \"PronunciationAssessment_Json\";\n  /**\n   * Pronunciation assessment parameters.\n   * This property is intended to be read-only. The SDK is using it internally.\n   * Added in version 1.15.0\n   */\n\n  PropertyId[PropertyId[\"PronunciationAssessment_Params\"] = 58] = \"PronunciationAssessment_Params\";\n  /**\n   * Version of Speaker Recognition API to use.\n   * Added in version 1.18.0\n   */\n\n  PropertyId[PropertyId[\"SpeakerRecognition_Api_Version\"] = 59] = \"SpeakerRecognition_Api_Version\";\n})(PropertyId || (PropertyId = {}));","map":{"version":3,"mappings":"AAAA;AACA;;AAEA;;;;AAIA,WAAYA,UAAZ;;AAAA,WAAYA,UAAZ,EAAsB;AAElB;;;;;;;AAOAA;AAEA;;;;;;;;AAOAA;AAEA;;;;;;;AAMAA;AAEA;;;;;;;;AAOAA;AAEA;;;;;AAIAA;AAEA;;;;;;;;AAOAA;AAEA;;;;;;;;AAOAA;AAEA;;;;;;;;AAOAA;AAEA;;;;;AAIAA;AAEA;;;;;;AAKAA;AAEA;;;;;;;AAMAA;AAEA;;;;;;;AAMAA;AAEA;;;;;;;AAMAA;AAEA;;;;;;;AAMAA;AAEA;;;;;;AAKAA;AAEA;;;;;;;AAMAA;AAEA;;;;;;;;AAOAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;;AAKAA;AAEA;;;;;;;AAMAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;;AAKAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;;AAKAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;;AAKAA;AAEA;;;;;;AAKAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;;AAKAA;AAEA;;;;;;AAKAA;AAEA;;;;;;AAKAA;AAEA;;;;;AAIAA;AAEA;;;;AAGAA;AAEA;;;;;AAIAA;AAEA;;;;;AAIAA;AAEA;;;;;;AAKAA;AAEA;;;;;;;;AAOAA;AAEA;;;;;;AAKAA;AAEA;;;;;;AAKAA;AAEA;;;;;;;;AAOAA;AAEA;;;;;;AAKAA;AAEA;;;;;;AAKAA;AAEA;;;;;AAIAA;AACH,CAhaD,EAAYA,UAAU,KAAVA,UAAU,MAAtB","names":["PropertyId"],"sources":["C:\\Users\\olesr\\OneDrive\\Documents\\webapp_educ\\educator\\node_modules\\microsoft-cognitiveservices-speech-sdk\\distrib\\es2015\\src\\sdk\\src\\sdk\\PropertyId.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT license.\r\n\r\n/**\r\n * Defines speech property ids.\r\n * @class PropertyId\r\n */\r\nexport enum PropertyId {\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service subscription Key. If you are using an intent recognizer, you need to specify\r\n     * to specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't\r\n     * have to use this property directly.\r\n     * Instead, use [[SpeechConfig.fromSubscription]].\r\n     * @member PropertyId.SpeechServiceConnection_Key\r\n     */\r\n    SpeechServiceConnection_Key = 0,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't\r\n     * have to use this property directly.\r\n     * Instead, use [[SpeechConfig.fromEndpoint]].\r\n     * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.\r\n     * @member PropertyId.SpeechServiceConnection_Endpoint\r\n     */\r\n    SpeechServiceConnection_Endpoint,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to\r\n     * use this property directly.\r\n     * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].\r\n     * @member PropertyId.SpeechServiceConnection_Region\r\n     */\r\n    SpeechServiceConnection_Region,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,\r\n     * you shouldn't have to use this property directly.\r\n     * Instead, use [[SpeechConfig.fromAuthorizationToken]], [[SpeechRecognizer.authorizationToken]],\r\n     * [[IntentRecognizer.authorizationToken]], [[TranslationRecognizer.authorizationToken]], [[SpeakerRecognizer.authorizationToken]].\r\n     * @member PropertyId.SpeechServiceAuthorization_Token\r\n     */\r\n    SpeechServiceAuthorization_Token,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service authorization type. Currently unused.\r\n     * @member PropertyId.SpeechServiceAuthorization_Type\r\n     */\r\n    SpeechServiceAuthorization_Type,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't\r\n     * have to use this property directly.\r\n     * Instead, use [[SpeechConfig.endpointId]].\r\n     * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.\r\n     * @member PropertyId.SpeechServiceConnection_EndpointId\r\n     */\r\n    SpeechServiceConnection_EndpointId,\r\n\r\n    /**\r\n     * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,\r\n     * you shouldn't have to use this property directly.\r\n     * Instead use [[SpeechTranslationConfig.addTargetLanguage]],\r\n     * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].\r\n     * @member PropertyId.SpeechServiceConnection_TranslationToLanguages\r\n     */\r\n    SpeechServiceConnection_TranslationToLanguages,\r\n\r\n    /**\r\n     * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this\r\n     * property directly.\r\n     * Instead, use [[SpeechTranslationConfig.voiceName]].\r\n     * NOTE: Valid voice names can be found <a href=\"https://aka.ms/csspeech/voicenames\">here</a>.\r\n     * @member PropertyId.SpeechServiceConnection_TranslationVoice\r\n     */\r\n    SpeechServiceConnection_TranslationVoice,\r\n\r\n    /**\r\n     * Translation features.\r\n     * @member PropertyId.SpeechServiceConnection_TranslationFeatures\r\n     */\r\n    SpeechServiceConnection_TranslationFeatures,\r\n\r\n    /**\r\n     * The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Instead, use [[LanguageUnderstandingModel]].\r\n     * @member PropertyId.SpeechServiceConnection_IntentRegion\r\n     */\r\n    SpeechServiceConnection_IntentRegion,\r\n\r\n    /**\r\n     * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\r\n     * You shouldn't have to use this property directly.\r\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\r\n     * Added in version 1.4.0.\r\n     */\r\n    SpeechServiceConnection_ProxyHostName,\r\n\r\n    /**\r\n     * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\r\n     * You shouldn't have to use this property directly.\r\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\r\n     * Added in version 1.4.0.\r\n     */\r\n    SpeechServiceConnection_ProxyPort,\r\n\r\n    /**\r\n     * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\r\n     * You shouldn't have to use this property directly.\r\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\r\n     * Added in version 1.4.0.\r\n     */\r\n    SpeechServiceConnection_ProxyUserName,\r\n\r\n    /**\r\n     * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\r\n     * You shouldn't have to use this property directly.\r\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\r\n     * Added in version 1.4.0.\r\n     */\r\n    SpeechServiceConnection_ProxyPassword,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service recognition Mode. Can be \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\".\r\n     * This property is intended to be read-only. The SDK is using it internally.\r\n     * @member PropertyId.SpeechServiceConnection_RecoMode\r\n     */\r\n    SpeechServiceConnection_RecoMode,\r\n\r\n    /**\r\n     * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property\r\n     * directly.\r\n     * Instead, use [[SpeechConfig.speechRecognitionLanguage]].\r\n     * @member PropertyId.SpeechServiceConnection_RecoLanguage\r\n     */\r\n    SpeechServiceConnection_RecoLanguage,\r\n\r\n    /**\r\n     * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream\r\n     * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this\r\n     * property directly.\r\n     * Instead use [[SessionEventArgs.sessionId]].\r\n     * @member PropertyId.Speech_SessionId\r\n     */\r\n    Speech_SessionId,\r\n\r\n    /**\r\n     * The spoken language to be synthesized (e.g. en-US)\r\n     * @member PropertyId.SpeechServiceConnection_SynthLanguage\r\n     */\r\n    SpeechServiceConnection_SynthLanguage,\r\n\r\n    /**\r\n     * The name of the TTS voice to be used for speech synthesis\r\n     * @member PropertyId.SpeechServiceConnection_SynthVoice\r\n     */\r\n    SpeechServiceConnection_SynthVoice,\r\n\r\n    /**\r\n     * The string to specify TTS output audio format\r\n     * @member PropertyId.SpeechServiceConnection_SynthOutputFormat\r\n     */\r\n    SpeechServiceConnection_SynthOutputFormat,\r\n\r\n    /**\r\n     * The list of comma separated languages used as possible source languages\r\n     * Added in version 1.13.0\r\n     * @member PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages\r\n     */\r\n    SpeechServiceConnection_AutoDetectSourceLanguages,\r\n\r\n    /**\r\n     * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have\r\n     * to use this property directly.\r\n     * Instead use [[SpeechConfig.outputFormat]].\r\n     * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse\r\n     */\r\n    SpeechServiceResponse_RequestDetailedResultTrueFalse,\r\n\r\n    /**\r\n     * The requested Cognitive Services Speech Service response output profanity level. Currently unused.\r\n     * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse\r\n     */\r\n    SpeechServiceResponse_RequestProfanityFilterTrueFalse,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.\r\n     * @member PropertyId.SpeechServiceResponse_JsonResult\r\n     */\r\n    SpeechServiceResponse_JsonResult,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to\r\n     * use this property directly. Instead use [[CancellationDetails.errorDetails]].\r\n     * @member PropertyId.SpeechServiceResponse_JsonErrorDetails\r\n     */\r\n    SpeechServiceResponse_JsonErrorDetails,\r\n\r\n    /**\r\n     * The cancellation reason. Currently unused.\r\n     * @member PropertyId.CancellationDetails_Reason\r\n     */\r\n    CancellationDetails_Reason,\r\n\r\n    /**\r\n     * The cancellation text. Currently unused.\r\n     * @member PropertyId.CancellationDetails_ReasonText\r\n     */\r\n    CancellationDetails_ReasonText,\r\n\r\n    /**\r\n     * The Cancellation detailed text. Currently unused.\r\n     * @member PropertyId.CancellationDetails_ReasonDetailedText\r\n     */\r\n    CancellationDetails_ReasonDetailedText,\r\n\r\n    /**\r\n     * The Language Understanding Service response output (in JSON format). Available via [[IntentRecognitionResult]]\r\n     * @member PropertyId.LanguageUnderstandingServiceResponse_JsonResult\r\n     */\r\n    LanguageUnderstandingServiceResponse_JsonResult,\r\n\r\n    /**\r\n     * The URL string built from speech configuration.\r\n     * This property is intended to be read-only. The SDK is using it internally.\r\n     * NOTE: Added in version 1.7.0.\r\n     */\r\n    SpeechServiceConnection_Url,\r\n\r\n    /**\r\n     * The initial silence timeout value (in milliseconds) used by the service.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceConnection_InitialSilenceTimeoutMs,\r\n\r\n    /**\r\n     * The end silence timeout value (in milliseconds) used by the service.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceConnection_EndSilenceTimeoutMs,\r\n\r\n    /**\r\n     * A boolean value specifying whether audio logging is enabled in the service or not.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceConnection_EnableAudioLogging,\r\n\r\n    /**\r\n     * The requested Cognitive Services Speech Service response output profanity setting.\r\n     * Allowed values are \"masked\", \"removed\", and \"raw\".\r\n     * Added in version 1.7.0.\r\n     */\r\n    SpeechServiceResponse_ProfanityOption,\r\n\r\n    /**\r\n     * A string value specifying which post processing option should be used by service.\r\n     * Allowed values are \"TrueText\".\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceResponse_PostProcessingOption,\r\n\r\n    /**\r\n     *  A boolean value specifying whether to include word-level timestamps in the response result.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceResponse_RequestWordLevelTimestamps,\r\n\r\n    /**\r\n     * The number of times a word has to be in partial results to be returned.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceResponse_StablePartialResultThreshold,\r\n\r\n    /**\r\n     * A string value specifying the output format option in the response result. Internal use only.\r\n     * Added in version 1.7.0.\r\n     */\r\n    SpeechServiceResponse_OutputFormatOption,\r\n\r\n    /**\r\n     * A boolean value to request for stabilizing translation partial results by omitting words in the end.\r\n     * Added in version 1.7.0.\r\n     */\r\n    SpeechServiceResponse_TranslationRequestStablePartialResult,\r\n\r\n    /**\r\n     * Identifier used to connect to the backend service.\r\n     * @member PropertyId.Conversation_ApplicationId\r\n     */\r\n    Conversation_ApplicationId,\r\n\r\n    /**\r\n     * Type of dialog backend to connect to.\r\n     * @member PropertyId.Conversation_DialogType\r\n     */\r\n    Conversation_DialogType,\r\n\r\n    /**\r\n     * Silence timeout for listening\r\n     * @member PropertyId.Conversation_Initial_Silence_Timeout\r\n     */\r\n    Conversation_Initial_Silence_Timeout,\r\n\r\n    /**\r\n     * From Id to add to speech recognition activities.\r\n     * @member PropertyId.Conversation_From_Id\r\n     */\r\n    Conversation_From_Id,\r\n\r\n    /**\r\n     * ConversationId for the session.\r\n     * @member PropertyId.Conversation_Conversation_Id\r\n     */\r\n    Conversation_Conversation_Id,\r\n\r\n    /**\r\n     * Comma separated list of custom voice deployment ids.\r\n     * @member PropertyId.Conversation_Custom_Voice_Deployment_Ids\r\n     */\r\n    Conversation_Custom_Voice_Deployment_Ids,\r\n\r\n    /**\r\n     * Speech activity template, stamp properties from the template on the activity generated by the service for speech.\r\n     * @member PropertyId.Conversation_Speech_Activity_Template\r\n     * Added in version 1.10.0.\r\n     */\r\n    Conversation_Speech_Activity_Template,\r\n\r\n    /**\r\n     * Enables or disables the receipt of turn status messages as obtained on the turnStatusReceived event.\r\n     * @member PropertyId.Conversation_Request_Bot_Status_Messages\r\n     * Added in version 1.15.0.\r\n     */\r\n    Conversation_Request_Bot_Status_Messages,\r\n\r\n    /**\r\n     * Specifies the connection ID to be provided in the Agent configuration message, e.g. a Direct Line token for\r\n     * channel authentication.\r\n     * Added in version 1.15.1.\r\n     */\r\n    Conversation_Agent_Connection_Id,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Instead, use [[SpeechConfig.fromHost]].\r\n     */\r\n    SpeechServiceConnection_Host,\r\n\r\n    /**\r\n     * Set the host for service calls to the Conversation Translator REST management and websocket calls.\r\n     */\r\n    ConversationTranslator_Host,\r\n\r\n    /**\r\n     * Optionally set the the host's display name.\r\n     * Used when joining a conversation.\r\n     */\r\n    ConversationTranslator_Name,\r\n\r\n    /**\r\n     * Optionally set a value for the X-CorrelationId request header.\r\n     * Used for troubleshooting errors in the server logs. It should be a valid guid.\r\n     */\r\n    ConversationTranslator_CorrelationId,\r\n\r\n    /**\r\n     * Set the conversation token to be sent to the speech service. This enables the\r\n     * service to service call from the speech service to the Conversation Translator service for relaying\r\n     * recognitions. For internal use.\r\n     */\r\n    ConversationTranslator_Token,\r\n\r\n    /**\r\n     * The reference text of the audio for pronunciation evaluation.\r\n     * For this and the following pronunciation assessment parameters, see\r\n     * https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_ReferenceText,\r\n\r\n    /**\r\n     * The point system for pronunciation score calibration (FivePoint or HundredMark).\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_GradingSystem,\r\n\r\n    /**\r\n     * The pronunciation evaluation granularity (Phoneme, Word, or FullText).\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_Granularity,\r\n\r\n    /**\r\n     * Defines if enable miscue calculation.\r\n     * With this enabled, the pronounced words will be compared to the reference text,\r\n     * and will be marked with omission/insertion based on the comparison. The default setting is False.\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_EnableMiscue,\r\n\r\n    /**\r\n     * The json string of pronunciation assessment parameters\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_Json,\r\n\r\n    /**\r\n     * Pronunciation assessment parameters.\r\n     * This property is intended to be read-only. The SDK is using it internally.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_Params,\r\n\r\n    /**\r\n     * Version of Speaker Recognition API to use.\r\n     * Added in version 1.18.0\r\n     */\r\n    SpeakerRecognition_Api_Version\r\n}\r\n"]},"metadata":{},"sourceType":"module"}