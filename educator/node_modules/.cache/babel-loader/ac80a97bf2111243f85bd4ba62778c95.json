{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\olesr\\\\OneDrive\\\\Documents\\\\webapp_educ\\\\educator\\\\src\\\\S2t.js\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\n//import { useRef } from \"react\";\nconst S2t = props => {\n  //const audioArray = useRef(null);\n  //async function convertToArray() {\n  //  const reader = new FileReader();\n  //  reader.onload = function (e) {\n  //    audioArray.current = e.target.result;\n  //  };\n  //  reader.readAsArrayBuffer(props.audio);\n  //}\n  //await convertToArray();\n  const sdk = require(\"microsoft-cognitiveservices-speech-sdk\");\n\n  const speechConfig = sdk.SpeechConfig.fromSubscription(\"453a4f6f9f194b9cb503930edaabb2d9\", \"eastus\");\n  speechConfig.speechRecognitionLanguage = \"de-CH\";\n  let audioConfig = sdk.AudioConfig.fromWavFileInput(props.audio);\n  let speechRecognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);\n  console.log(audioConfig); //speechRecognizer.recognizeOnceAsync((result) => {\n  //  switch (result.reason) {\n  //    case sdk.ResultReason.RecognizedSpeech:\n  //      console.log(`RECOGNIZED: Text=${result.text}`);\n  //      break;\n  //    case sdk.ResultReason.NoMatch:\n  //      console.log(\"NOMATCH: Speech could not be recognized.\");\n  //      break;\n  //    case sdk.ResultReason.Canceled:\n  //      const cancellation = CancellationDetails.fromResult(result);\n  //      console.log(`CANCELED: Reason=${cancellation.reason}`);\n  //\n  //      if (cancellation.reason == sdk.CancellationReason.Error) {\n  //        console.log(`CANCELED: ErrorCode=${cancellation.ErrorCode}`);\n  //        console.log(`CANCELED: ErrorDetails=${cancellation.errorDetails}`);\n  //        console.log(\n  //          \"CANCELED: Did you update the key and location/region info?\"\n  //        );\n  //      }\n  //      break;\n  //  }\n  //  speechRecognizer.close();\n  //});\n\n  return sdk && /*#__PURE__*/_jsxDEV(\"h1\", {\n    children: \"works\"\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 50,\n    columnNumber: 17\n  }, this);\n};\n\n_c = S2t;\nexport default S2t;\n\nvar _c;\n\n$RefreshReg$(_c, \"S2t\");","map":{"version":3,"sources":["C:/Users/olesr/OneDrive/Documents/webapp_educ/educator/src/S2t.js"],"names":["S2t","props","sdk","require","speechConfig","SpeechConfig","fromSubscription","speechRecognitionLanguage","audioConfig","AudioConfig","fromWavFileInput","audio","speechRecognizer","SpeechRecognizer","console","log"],"mappings":";;;AAAA;AAEA,MAAMA,GAAG,GAAIC,KAAD,IAAW;AACrB;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA,QAAMC,GAAG,GAAGC,OAAO,CAAC,wCAAD,CAAnB;;AACA,QAAMC,YAAY,GAAGF,GAAG,CAACG,YAAJ,CAAiBC,gBAAjB,CACnB,kCADmB,EAEnB,QAFmB,CAArB;AAIAF,EAAAA,YAAY,CAACG,yBAAb,GAAyC,OAAzC;AAEA,MAAIC,WAAW,GAAGN,GAAG,CAACO,WAAJ,CAAgBC,gBAAhB,CAAiCT,KAAK,CAACU,KAAvC,CAAlB;AACA,MAAIC,gBAAgB,GAAG,IAAIV,GAAG,CAACW,gBAAR,CAAyBT,YAAzB,EAAuCI,WAAvC,CAAvB;AACAM,EAAAA,OAAO,CAACC,GAAR,CAAYP,WAAZ,EArBqB,CAuBrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAAON,GAAG,iBAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAAd;AACD,CAhDD;;KAAMF,G;AAkDN,eAAeA,GAAf","sourcesContent":["//import { useRef } from \"react\";\r\n\r\nconst S2t = (props) => {\r\n  //const audioArray = useRef(null);\r\n\r\n  //async function convertToArray() {\r\n  //  const reader = new FileReader();\r\n  //  reader.onload = function (e) {\r\n  //    audioArray.current = e.target.result;\r\n  //  };\r\n  //  reader.readAsArrayBuffer(props.audio);\r\n  //}\r\n\r\n  //await convertToArray();\r\n  const sdk = require(\"microsoft-cognitiveservices-speech-sdk\");\r\n  const speechConfig = sdk.SpeechConfig.fromSubscription(\r\n    \"453a4f6f9f194b9cb503930edaabb2d9\",\r\n    \"eastus\"\r\n  );\r\n  speechConfig.speechRecognitionLanguage = \"de-CH\";\r\n\r\n  let audioConfig = sdk.AudioConfig.fromWavFileInput(props.audio);\r\n  let speechRecognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);\r\n  console.log(audioConfig);\r\n\r\n  //speechRecognizer.recognizeOnceAsync((result) => {\r\n  //  switch (result.reason) {\r\n  //    case sdk.ResultReason.RecognizedSpeech:\r\n  //      console.log(`RECOGNIZED: Text=${result.text}`);\r\n  //      break;\r\n  //    case sdk.ResultReason.NoMatch:\r\n  //      console.log(\"NOMATCH: Speech could not be recognized.\");\r\n  //      break;\r\n  //    case sdk.ResultReason.Canceled:\r\n  //      const cancellation = CancellationDetails.fromResult(result);\r\n  //      console.log(`CANCELED: Reason=${cancellation.reason}`);\r\n  //\r\n  //      if (cancellation.reason == sdk.CancellationReason.Error) {\r\n  //        console.log(`CANCELED: ErrorCode=${cancellation.ErrorCode}`);\r\n  //        console.log(`CANCELED: ErrorDetails=${cancellation.errorDetails}`);\r\n  //        console.log(\r\n  //          \"CANCELED: Did you update the key and location/region info?\"\r\n  //        );\r\n  //      }\r\n  //      break;\r\n  //  }\r\n  //  speechRecognizer.close();\r\n  //});\r\n\r\n  return sdk && <h1>works</h1>;\r\n};\r\n\r\nexport default S2t;\r\n"]},"metadata":{},"sourceType":"module"}